{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional functions I used\n",
    "This file contains the functions used for calculating both the word error rate and character error rate. <br/>\n",
    "It also contains the code I used to create the transcriptions belonging to the audio files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for calculating the WER and CER\n",
    "It uses the calculate_wer function from espnet:\n",
    "https://github.com/espnet/espnet/blob/master/espnet/nets/e2e_asr_common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(seqs_hat, seqs_true):\n",
    "    #This function originates from: https://github.com/espnet/espnet/blob/master/espnet/nets/e2e_asr_common.py\n",
    "    \"\"\"Calculate sentence-level WER score.\n",
    "    :param list seqs_hat: prediction\n",
    "    :param list seqs_true: reference\n",
    "    :return: average sentence-level WER score\n",
    "    :rtype float\n",
    "    \"\"\"\n",
    "    import editdistance\n",
    "\n",
    "    word_eds, word_ref_lens = [], []\n",
    "    for i, seq_hat_text in enumerate(seqs_hat):\n",
    "        seq_true_text = seqs_true[i]\n",
    "        hyp_words = [item.lower() for item in seq_hat_text.split()]\n",
    "        ref_words = [item.lower() for item in seq_true_text.split()]\n",
    "        word_eds.append(editdistance.eval(hyp_words, ref_words))\n",
    "        word_ref_lens.append(len(ref_words))\n",
    "    return round((float(sum(word_eds)) / sum(word_ref_lens)) * 100, 2)\n",
    "\n",
    "def open_folder_and_return_lines(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "def calculate_wer_character_level(seqs_hat, seqs_true):\n",
    "    #same function but changed to make it look at character level\n",
    "    import editdistance\n",
    "    \n",
    "    word_eds, word_ref_lens = [], []\n",
    "    for i, seq_hat_text in enumerate(seqs_hat):\n",
    "        seq_true_text = seqs_true[i]\n",
    "        hyp_words = [item.lower() for item in seq_hat_text.split()]\n",
    "        ref_words = [item.lower() for item in seq_true_text.split()]\n",
    "        \n",
    "        #instead of having a list of words, it has all the words in a single sentence\n",
    "        hyp_words = \" \".join(hyp_words)\n",
    "        ref_words = \" \".join(ref_words)\n",
    "        word_eds.append(editdistance.eval(hyp_words, ref_words))\n",
    "        word_ref_lens.append(len(ref_words))\n",
    "    return round((float(sum(word_eds)) / sum(word_ref_lens)) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WER for speaker M07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M07_0.75x\n",
      "original\n",
      "237.37\n",
      "\n",
      "\n",
      "M07_0.75x\n",
      "converted\n",
      "268.4\n",
      "\n",
      "\n",
      "M07_original\n",
      "original\n",
      "232.49\n",
      "\n",
      "\n",
      "M07_original\n",
      "converted\n",
      "267.11\n",
      "\n",
      "\n",
      "M07_1.25x\n",
      "original\n",
      "230.92\n",
      "\n",
      "\n",
      "M07_1.25x\n",
      "converted\n",
      "252.04\n",
      "\n",
      "\n",
      "M07_1.5x\n",
      "original\n",
      "224.59\n",
      "\n",
      "\n",
      "M07_1.5x\n",
      "converted\n",
      "228.74\n",
      "\n",
      "\n",
      "M07_1.75x\n",
      "original\n",
      "213.05\n",
      "\n",
      "\n",
      "M07_1.75x\n",
      "converted\n",
      "208.96\n",
      "\n",
      "\n",
      "M07_2x\n",
      "original\n",
      "202.46\n",
      "\n",
      "\n",
      "M07_2x\n",
      "converted\n",
      "195.52\n",
      "\n",
      "\n",
      "lowest value\n",
      "M07_2xconverted 195.52\n",
      "control group:\n",
      "69.69\n"
     ]
    }
   ],
   "source": [
    "folder = \"predictions/\"\n",
    "paths = ['M07_0.75x', 'M07_original', 'M07_1.25x', 'M07_1.5x', 'M07_1.75x', 'M07_2x']\n",
    "adds = [\"_predictions_original.txt\", \"_predictions_transformed.txt\", \"_transcription.txt\"]\n",
    "\n",
    "lowest = 1000\n",
    "path_lowest = \"path\"\n",
    "for path in paths:\n",
    "    transcriptions = open_folder_and_return_lines(folder + paths[0] + adds[2])\n",
    "    original = open_folder_and_return_lines(folder + path + adds[0])\n",
    "    converted = open_folder_and_return_lines(folder + path + adds[1])\n",
    "    \n",
    "    print(path)\n",
    "    print(\"original\")\n",
    "    print(calculate_wer(original, transcriptions))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(path)\n",
    "    print(\"converted\")\n",
    "    print(calculate_wer(converted, transcriptions))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if calculate_wer(original, transcriptions) < lowest:\n",
    "        path_lowest = path + \"original\"\n",
    "        lowest =  calculate_wer(original, transcriptions)\n",
    "    if calculate_wer(converted, transcriptions) < lowest:\n",
    "        path_lowest = path + \"converted\"\n",
    "        lowest = calculate_wer(converted, transcriptions)\n",
    "\n",
    "print(\"lowest value\")\n",
    "print(path_lowest, lowest)\n",
    "\n",
    "print(\"control group:\")\n",
    "transcriptions = open_folder_and_return_lines(\"transcriptions_control.txt\")\n",
    "predictions = open_folder_and_return_lines(\"predictions_control.txt\")\n",
    "print(calculate_wer(predictions, transcriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CER for speaker M07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M07_0.75x\n",
      "original\n",
      "169.95\n",
      "\n",
      "\n",
      "M07_0.75x\n",
      "converted\n",
      "195.05\n",
      "\n",
      "\n",
      "M07_original\n",
      "original\n",
      "162.03\n",
      "\n",
      "\n",
      "M07_original\n",
      "converted\n",
      "189.44\n",
      "\n",
      "\n",
      "M07_1.25x\n",
      "original\n",
      "160.11\n",
      "\n",
      "\n",
      "M07_1.25x\n",
      "converted\n",
      "174.74\n",
      "\n",
      "\n",
      "M07_1.5x\n",
      "original\n",
      "152.16\n",
      "\n",
      "\n",
      "M07_1.5x\n",
      "converted\n",
      "159.15\n",
      "\n",
      "\n",
      "M07_1.75x\n",
      "original\n",
      "145.44\n",
      "\n",
      "\n",
      "M07_1.75x\n",
      "converted\n",
      "147.03\n",
      "\n",
      "\n",
      "M07_2x\n",
      "original\n",
      "139.2\n",
      "\n",
      "\n",
      "M07_2x\n",
      "converted\n",
      "136.72\n",
      "\n",
      "\n",
      "lowest value\n",
      "M07_2xconverted 136.72\n",
      "control group:\n",
      "30.53\n"
     ]
    }
   ],
   "source": [
    "folder = \"predictions/\"\n",
    "paths = ['M07_0.75x', 'M07_original', 'M07_1.25x', 'M07_1.5x', 'M07_1.75x', 'M07_2x']\n",
    "adds = [\"_predictions_original.txt\", \"_predictions_transformed.txt\", \"_transcription.txt\"]\n",
    "\n",
    "lowest = 1000\n",
    "path_lowest = \"path\"\n",
    "for path in paths:\n",
    "    transcriptions = open_folder_and_return_lines(folder + paths[0] + adds[2])\n",
    "    original = open_folder_and_return_lines(folder + path + adds[0])\n",
    "    converted = open_folder_and_return_lines(folder + path + adds[1])\n",
    "    \n",
    "    print(path)\n",
    "    print(\"original\")\n",
    "    print(calculate_wer_character_level(original, transcriptions))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(path)\n",
    "    print(\"converted\")\n",
    "    print(calculate_wer_character_level(converted, transcriptions))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if calculate_wer_character_level(original, transcriptions) < lowest:\n",
    "        path_lowest = path + \"original\"\n",
    "        lowest =  calculate_wer_character_level(original, transcriptions)\n",
    "    if calculate_wer_character_level(converted, transcriptions) < lowest:\n",
    "        path_lowest = path + \"converted\"\n",
    "        lowest = calculate_wer_character_level(converted, transcriptions)\n",
    "\n",
    "print(\"lowest value\")\n",
    "print(path_lowest, lowest)\n",
    "\n",
    "print(\"control group:\")\n",
    "transcriptions = open_folder_and_return_lines(\"transcriptions_control.txt\")\n",
    "predictions = open_folder_and_return_lines(\"predictions_control.txt\")\n",
    "print(calculate_wer_character_level(predictions, transcriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the transcriptions for experiment M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        WORD FILE NAME\n",
      "0     Three        D3\n",
      "1      Nine        D9\n",
      "2      Zero        D0\n",
      "3       Six        D6\n",
      "4     Seven        D7\n",
      "..      ...       ...\n",
      "450    fire   B3_UW96\n",
      "451   watch   B3_UW97\n",
      "452   ahead   B3_UW98\n",
      "453    away   B3_UW99\n",
      "454  crayon  B3_UW100\n",
      "\n",
      "[455 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('speaker_wordlist.xls', sheet_name='Word_filename')\n",
    "\n",
    "print(df.head)\n",
    "list_of_words = []\n",
    "list_of_index = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    list_of_words.append(row.WORD)\n",
    "    list_of_index.append(row._2)\n",
    "    \n",
    "    \n",
    "folder = \"uaspeech_experiments_M5/\"\n",
    "paths = ['M05_0.75x/', 'M05_1.25x/', 'M05_1.5x/', 'M05_1.75x/', 'M05_2.0x/', 'M05_1.0x/']\n",
    "file_name = 'M05_wav_list.txt'\n",
    "save_location = \"predictions_m05/\"\n",
    "\n",
    "for path in paths:\n",
    "    loc = folder + path + file_name\n",
    "    \n",
    "    with open(loc) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    list_of_transcriptions = []\n",
    "    \n",
    "    for name in lines:\n",
    "        for i in range(len(list_of_words)):\n",
    "            string1 = \"_\" + list_of_index[i] + \"_\"\n",
    "            if string1 in name:\n",
    "                list_of_transcriptions.append(list_of_words[i])\n",
    "    \n",
    "    save_loc = save_location + path[:-1] + \"_transcription.txt\"\n",
    "    with open(save_loc, 'w') as output:\n",
    "        for transcription in list_of_transcriptions:\n",
    "            output.write(transcription)\n",
    "            output.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WER for speaker M05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M05_0.75x\n",
      "original\n",
      "249.92\n",
      "\n",
      "\n",
      "M05_0.75x\n",
      "converted\n",
      "317.09\n",
      "\n",
      "\n",
      "M05_1.0x\n",
      "original\n",
      "241.34\n",
      "\n",
      "\n",
      "M05_1.0x\n",
      "converted\n",
      "288.52\n",
      "\n",
      "\n",
      "M05_1.25x\n",
      "original\n",
      "248.12\n",
      "\n",
      "\n",
      "M05_1.25x\n",
      "converted\n",
      "261.68\n",
      "\n",
      "\n",
      "M05_1.5x\n",
      "original\n",
      "238.32\n",
      "\n",
      "\n",
      "M05_1.5x\n",
      "converted\n",
      "236.69\n",
      "\n",
      "\n",
      "M05_1.75x\n",
      "original\n",
      "233.56\n",
      "\n",
      "\n",
      "M05_1.75x\n",
      "converted\n",
      "216.08\n",
      "\n",
      "\n",
      "M05_2.0x\n",
      "original\n",
      "219.83\n",
      "\n",
      "\n",
      "M05_2.0x\n",
      "converted\n",
      "199.83\n",
      "\n",
      "\n",
      "lowest value\n",
      "M05_2.0xconverted 199.83\n"
     ]
    }
   ],
   "source": [
    "folder = \"predictions_m05/\"\n",
    "paths = ['M05_0.75x', 'M05_1.0x', 'M05_1.25x', 'M05_1.5x', 'M05_1.75x', 'M05_2.0x']\n",
    "adds = [\"_predictions_original.txt\", \"_predictions_transformed.txt\", \"_transcription.txt\"]\n",
    "\n",
    "lowest = 1000\n",
    "path_lowest = \"path\"\n",
    "for path in paths:\n",
    "    transcriptions = open_folder_and_return_lines(folder + paths[0] + adds[2])\n",
    "    original = open_folder_and_return_lines(folder + path + adds[0])\n",
    "    converted = open_folder_and_return_lines(folder + path + adds[1])\n",
    "    \n",
    "    print(path)\n",
    "    print(\"original\")\n",
    "    print(calculate_wer(original, transcriptions))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(path)\n",
    "    print(\"converted\")\n",
    "    print(calculate_wer(converted, transcriptions))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if calculate_wer(original, transcriptions) < lowest:\n",
    "        path_lowest = path + \"original\"\n",
    "        lowest =  calculate_wer(original, transcriptions)\n",
    "    if calculate_wer(converted, transcriptions) < lowest:\n",
    "        path_lowest = path + \"converted\"\n",
    "        lowest = calculate_wer(converted, transcriptions)\n",
    "\n",
    "print(\"lowest value\")\n",
    "print(path_lowest, lowest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CER for speaker M05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M05_0.75x\n",
      "original\n",
      "170.81\n",
      "\n",
      "\n",
      "M05_0.75x\n",
      "converted\n",
      "223.73\n",
      "\n",
      "\n",
      "M05_1.0x\n",
      "original\n",
      "158.42\n",
      "\n",
      "\n",
      "M05_1.0x\n",
      "converted\n",
      "196.1\n",
      "\n",
      "\n",
      "M05_1.25x\n",
      "original\n",
      "160.06\n",
      "\n",
      "\n",
      "M05_1.25x\n",
      "converted\n",
      "175.48\n",
      "\n",
      "\n",
      "M05_1.5x\n",
      "original\n",
      "151.42\n",
      "\n",
      "\n",
      "M05_1.5x\n",
      "converted\n",
      "156.48\n",
      "\n",
      "\n",
      "M05_1.75x\n",
      "original\n",
      "148.95\n",
      "\n",
      "\n",
      "M05_1.75x\n",
      "converted\n",
      "143.87\n",
      "\n",
      "\n",
      "M05_2.0x\n",
      "original\n",
      "138.7\n",
      "\n",
      "\n",
      "M05_2.0x\n",
      "converted\n",
      "133.53\n",
      "\n",
      "\n",
      "lowest value\n",
      "M05_2.0xconverted 133.53\n"
     ]
    }
   ],
   "source": [
    "folder = \"predictions_m05/\"\n",
    "paths = ['M05_0.75x', 'M05_1.0x', 'M05_1.25x', 'M05_1.5x', 'M05_1.75x', 'M05_2.0x']\n",
    "adds = [\"_predictions_original.txt\", \"_predictions_transformed.txt\", \"_transcription.txt\"]\n",
    "\n",
    "lowest = 1000\n",
    "path_lowest = \"path\"\n",
    "for path in paths:\n",
    "    transcriptions = open_folder_and_return_lines(folder + paths[0] + adds[2])\n",
    "    original = open_folder_and_return_lines(folder + path + adds[0])\n",
    "    converted = open_folder_and_return_lines(folder + path + adds[1])\n",
    "    \n",
    "    print(path)\n",
    "    print(\"original\")\n",
    "    print(calculate_wer_character_level(original, transcriptions))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(path)\n",
    "    print(\"converted\")\n",
    "    print(calculate_wer_character_level(converted, transcriptions))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if calculate_wer_character_level(original, transcriptions) < lowest:\n",
    "        path_lowest = path + \"original\"\n",
    "        lowest =  calculate_wer_character_level(original, transcriptions)\n",
    "    if calculate_wer_character_level(converted, transcriptions) < lowest:\n",
    "        path_lowest = path + \"converted\"\n",
    "        lowest = calculate_wer_character_level(converted, transcriptions)\n",
    "\n",
    "print(\"lowest value\")\n",
    "print(path_lowest, lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
